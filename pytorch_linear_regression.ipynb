{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Variable demo\n",
    "# 导入模块\n",
    "# -*- coding: utf-8 -*-\n",
    "import torch as T\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.], requires_grad=True)\n",
      "tensor([5.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Variabel会放入一个计算图，然后进行前向传播，反向传播以及自动求导\n",
    "# 一个Variable里面包含着三个属性，data，grad和creator，\n",
    "# 其中creator表示得到这个Variabel的操作，比如乘法或者加法等等，\n",
    "# grad表示方向传播的梯度，data表示取出这个Variabel里面的数据\n",
    "\n",
    "# requires_grad 表示是否对其求梯度，默认是True\n",
    "x = Variable(T.Tensor([3]), requires_grad=True)\n",
    "y = Variable(T.Tensor([5]), requires_grad=True)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "z = x * x * x + 3 * y + 4\n",
    "\n",
    "# 对x和y分别求导\n",
    "print(z.backward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dz/dx:tensor([27.])\n",
      "dz/dy:tensor([3.])\n"
     ]
    }
   ],
   "source": [
    "# x的导数和y的导数\n",
    "print('dz/dx:{}'.format(x.grad.data))\n",
    "print('dz/dy:{}'.format(y.grad.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 线性回归示例\n",
    "# 数据\n",
    "x_data = [1.0, 2.0, 3.0, 4.0, 6.0]\n",
    "y_data = [3.1, 5.0, 6.9, 9.2, 13.1]\n",
    "\n",
    "# 绘制散点图\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x_data, y_data)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Variable(T.Tensor([0.0]), requires_grad=True)\n",
    "b = Variable(T.Tensor([0.0]), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward computation\n",
    "def forward(x):\n",
    "    return x * w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss function\n",
    "def loss(x, y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y) * (y_pred - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict(before training) 5 tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "# before training\n",
    "print(\"predict(before training)\", 5, forward(5).data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.6100], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-6.2000])\n",
      "tensor([23.1746], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-19.2560])\n",
      "tensor([35.7370], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([-35.8682])\n",
      "tensor([41.8504], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-51.7535])\n",
      "tensor([34.9058], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([-70.8973])\n",
      "progress:  0 tensor(34.9058)\n",
      "tensor([0.5400], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-1.4697])\n",
      "tensor([0.5640], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-3.0041])\n",
      "tensor([0.4781], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([-4.1486])\n",
      "tensor([0.8596], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-7.4174])\n",
      "tensor([0.2618], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([-6.1396])\n",
      "progress:  1 tensor(0.2618)\n",
      "tensor([0.1943], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.8815])\n",
      "tensor([0.0639], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-1.0110])\n",
      "tensor([0.0022], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([-0.2821])\n",
      "tensor([0.0647], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-2.0346])\n",
      "tensor([0.0194], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.6730])\n",
      "progress:  2 tensor(0.0194)\n",
      "tensor([0.1586], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.7966])\n",
      "tensor([0.0351], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.7499])\n",
      "tensor([0.0011], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.2019])\n",
      "tensor([0.0298], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3819])\n",
      "tensor([0.0459], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([2.5720])\n",
      "progress:  3 tensor(0.0459)\n",
      "tensor([0.1494], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.7730])\n",
      "tensor([0.0306], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.6995])\n",
      "tensor([0.0021], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.2747])\n",
      "tensor([0.0266], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3036])\n",
      "tensor([0.0481], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([2.6326])\n",
      "progress:  4 tensor(0.0481)\n",
      "tensor([0.1434], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.7573])\n",
      "tensor([0.0285], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.6752])\n",
      "tensor([0.0025], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.2973])\n",
      "tensor([0.0262], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.2950])\n",
      "tensor([0.0467], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([2.5926])\n",
      "progress:  5 tensor(0.0467)\n",
      "tensor([0.1379], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.7428])\n",
      "tensor([0.0268], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.6544])\n",
      "tensor([0.0027], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.3135])\n",
      "tensor([0.0262], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.2948])\n",
      "tensor([0.0448], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([2.5413])\n",
      "progress:  6 tensor(0.0448)\n",
      "tensor([0.1328], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.7287])\n",
      "tensor([0.0252], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.6345])\n",
      "tensor([0.0030], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.3286])\n",
      "tensor([0.0262], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.2957])\n",
      "tensor([0.0431], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([2.4898])\n",
      "progress:  7 tensor(0.0431)\n",
      "tensor([0.1278], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.7150])\n",
      "tensor([0.0236], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.6151])\n",
      "tensor([0.0033], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.3432])\n",
      "tensor([0.0263], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.2966])\n",
      "tensor([0.0413], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([2.4394])\n",
      "progress:  8 tensor(0.0413)\n",
      "tensor([0.1231], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.7016])\n",
      "tensor([0.0222], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.5961])\n",
      "tensor([0.0036], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.3575])\n",
      "tensor([0.0263], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.2976])\n",
      "tensor([0.0397], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([2.3901])\n",
      "progress:  9 tensor(0.0397)\n",
      "tensor([0.1185], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.6885])\n",
      "tensor([0.0209], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.5776])\n",
      "tensor([0.0038], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.3715])\n",
      "tensor([0.0263], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.2985])\n",
      "tensor([0.0381], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([2.3419])\n",
      "progress:  10 tensor(0.0381)\n",
      "tensor([0.1142], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.6758])\n",
      "tensor([0.0196], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.5595])\n",
      "tensor([0.0041], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.3851])\n",
      "tensor([0.0264], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.2994])\n",
      "tensor([0.0366], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([2.2948])\n",
      "progress:  11 tensor(0.0366)\n",
      "tensor([0.1100], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.6633])\n",
      "tensor([0.0184], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.5419])\n",
      "tensor([0.0044], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.3984])\n",
      "tensor([0.0264], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3003])\n",
      "tensor([0.0351], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([2.2489])\n",
      "progress:  12 tensor(0.0351)\n",
      "tensor([0.1060], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.6511])\n",
      "tensor([0.0172], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.5246])\n",
      "tensor([0.0047], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.4114])\n",
      "tensor([0.0265], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3012])\n",
      "tensor([0.0337], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([2.2040])\n",
      "progress:  13 tensor(0.0337)\n",
      "tensor([0.1021], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.6392])\n",
      "tensor([0.0161], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.5078])\n",
      "tensor([0.0050], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.4241])\n",
      "tensor([0.0265], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3020])\n",
      "tensor([0.0324], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([2.1601])\n",
      "progress:  14 tensor(0.0324)\n",
      "tensor([0.0984], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.6275])\n",
      "tensor([0.0151], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.4913])\n",
      "tensor([0.0053], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.4366])\n",
      "tensor([0.0265], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3028])\n",
      "tensor([0.0311], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([2.1173])\n",
      "progress:  15 tensor(0.0311)\n",
      "tensor([0.0949], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.6162])\n",
      "tensor([0.0141], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.4752])\n",
      "tensor([0.0056], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.4487])\n",
      "tensor([0.0266], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3036])\n",
      "tensor([0.0299], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([2.0755])\n",
      "progress:  16 tensor(0.0299)\n",
      "tensor([0.0915], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.6051])\n",
      "tensor([0.0132], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.4595])\n",
      "tensor([0.0059], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.4605])\n",
      "tensor([0.0266], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3044])\n",
      "tensor([0.0287], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([2.0346])\n",
      "progress:  17 tensor(0.0287)\n",
      "tensor([0.0883], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.5942])\n",
      "tensor([0.0123], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.4442])\n",
      "tensor([0.0062], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.4721])\n",
      "tensor([0.0266], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3052])\n",
      "tensor([0.0276], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.9947])\n",
      "progress:  18 tensor(0.0276)\n",
      "tensor([0.0852], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.5836])\n",
      "tensor([0.0115], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.4292])\n",
      "tensor([0.0065], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.4834])\n",
      "tensor([0.0266], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3060])\n",
      "tensor([0.0266], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.9557])\n",
      "progress:  19 tensor(0.0266)\n",
      "tensor([0.0822], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.5733])\n",
      "tensor([0.0107], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.4146])\n",
      "tensor([0.0068], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.4944])\n",
      "tensor([0.0267], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3067])\n",
      "tensor([0.0255], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.9177])\n",
      "progress:  20 tensor(0.0255)\n",
      "tensor([0.0793], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.5632])\n",
      "tensor([0.0100], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.4003])\n",
      "tensor([0.0071], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.5052])\n",
      "tensor([0.0267], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3074])\n",
      "tensor([0.0246], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.8805])\n",
      "progress:  21 tensor(0.0246)\n",
      "tensor([0.0765], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.5533])\n",
      "tensor([0.0093], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.3863])\n",
      "tensor([0.0074], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.5158])\n",
      "tensor([0.0267], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3081])\n",
      "tensor([0.0236], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.8441])\n",
      "progress:  22 tensor(0.0236)\n",
      "tensor([0.0739], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.5437])\n",
      "tensor([0.0087], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.3727])\n",
      "tensor([0.0077], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.5260])\n",
      "tensor([0.0268], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3088])\n",
      "tensor([0.0227], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.8086])\n",
      "progress:  23 tensor(0.0227)\n",
      "tensor([0.0714], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.5342])\n",
      "tensor([0.0081], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.3593])\n",
      "tensor([0.0080], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.5361])\n",
      "tensor([0.0268], grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad: 4.0 9.2 tensor([-1.3095])\n",
      "tensor([0.0219], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.7740])\n",
      "progress:  24 tensor(0.0219)\n",
      "tensor([0.0689], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.5250])\n",
      "tensor([0.0075], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.3463])\n",
      "tensor([0.0083], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.5459])\n",
      "tensor([0.0268], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3101])\n",
      "tensor([0.0210], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.7401])\n",
      "progress:  25 tensor(0.0210)\n",
      "tensor([0.0666], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.5161])\n",
      "tensor([0.0070], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.3336])\n",
      "tensor([0.0086], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.5555])\n",
      "tensor([0.0268], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3108])\n",
      "tensor([0.0202], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.7071])\n",
      "progress:  26 tensor(0.0202)\n",
      "tensor([0.0643], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.5073])\n",
      "tensor([0.0064], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.3212])\n",
      "tensor([0.0089], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.5648])\n",
      "tensor([0.0269], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3114])\n",
      "tensor([0.0195], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.6748])\n",
      "progress:  27 tensor(0.0195)\n",
      "tensor([0.0622], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.4987])\n",
      "tensor([0.0060], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.3091])\n",
      "tensor([0.0092], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.5740])\n",
      "tensor([0.0269], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3120])\n",
      "tensor([0.0188], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.6432])\n",
      "progress:  28 tensor(0.0188)\n",
      "tensor([0.0601], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.4903])\n",
      "tensor([0.0055], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.2972])\n",
      "tensor([0.0094], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.5829])\n",
      "tensor([0.0269], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3126])\n",
      "tensor([0.0181], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.6124])\n",
      "progress:  29 tensor(0.0181)\n",
      "tensor([0.0581], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.4822])\n",
      "tensor([0.0051], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.2857])\n",
      "tensor([0.0097], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.5917])\n",
      "tensor([0.0269], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3132])\n",
      "tensor([0.0174], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.5823])\n",
      "progress:  30 tensor(0.0174)\n",
      "tensor([0.0562], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.4742])\n",
      "tensor([0.0047], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.2744])\n",
      "tensor([0.0100], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.6002])\n",
      "tensor([0.0270], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3137])\n",
      "tensor([0.0167], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.5529])\n",
      "progress:  31 tensor(0.0167)\n",
      "tensor([0.0544], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.4664])\n",
      "tensor([0.0043], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.2633])\n",
      "tensor([0.0103], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.6085])\n",
      "tensor([0.0270], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3143])\n",
      "tensor([0.0161], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.5241])\n",
      "progress:  32 tensor(0.0161)\n",
      "tensor([0.0526], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.4587])\n",
      "tensor([0.0040], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.2525])\n",
      "tensor([0.0106], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.6166])\n",
      "tensor([0.0270], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3148])\n",
      "tensor([0.0155], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.4961])\n",
      "progress:  33 tensor(0.0155)\n",
      "tensor([0.0509], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.4513])\n",
      "tensor([0.0037], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.2420])\n",
      "tensor([0.0108], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.6246])\n",
      "tensor([0.0270], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3154])\n",
      "tensor([0.0150], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.4687])\n",
      "progress:  34 tensor(0.0150)\n",
      "tensor([0.0493], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.4440])\n",
      "tensor([0.0034], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.2317])\n",
      "tensor([0.0111], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.6323])\n",
      "tensor([0.0271], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3159])\n",
      "tensor([0.0144], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.4419])\n",
      "progress:  35 tensor(0.0144)\n",
      "tensor([0.0477], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.4369])\n",
      "tensor([0.0031], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.2217])\n",
      "tensor([0.0114], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.6399])\n",
      "tensor([0.0271], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3164])\n",
      "tensor([0.0139], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.4158])\n",
      "progress:  36 tensor(0.0139)\n",
      "tensor([0.0462], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.4300])\n",
      "tensor([0.0028], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.2118])\n",
      "tensor([0.0116], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.6473])\n",
      "tensor([0.0271], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3169])\n",
      "tensor([0.0134], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.3902])\n",
      "progress:  37 tensor(0.0134)\n",
      "tensor([0.0448], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.4232])\n",
      "tensor([0.0026], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.2023])\n",
      "tensor([0.0119], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.6546])\n",
      "tensor([0.0271], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3174])\n",
      "tensor([0.0129], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.3653])\n",
      "progress:  38 tensor(0.0129)\n",
      "tensor([0.0434], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.4166])\n",
      "tensor([0.0023], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.1929])\n",
      "tensor([0.0122], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.6616])\n",
      "tensor([0.0271], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3178])\n",
      "tensor([0.0125], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.3409])\n",
      "progress:  39 tensor(0.0125)\n",
      "tensor([0.0421], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.4101])\n",
      "tensor([0.0021], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.1838])\n",
      "tensor([0.0124], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.6685])\n",
      "tensor([0.0272], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3183])\n",
      "tensor([0.0120], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.3171])\n",
      "progress:  40 tensor(0.0120)\n",
      "tensor([0.0408], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.4038])\n",
      "tensor([0.0019], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.1748])\n",
      "tensor([0.0127], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.6752])\n",
      "tensor([0.0272], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3187])\n",
      "tensor([0.0116], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.2939])\n",
      "progress:  41 tensor(0.0116)\n",
      "tensor([0.0395], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.3976])\n",
      "tensor([0.0017], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.1661])\n",
      "tensor([0.0129], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.6818])\n",
      "tensor([0.0272], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3192])\n",
      "tensor([0.0112], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.2712])\n",
      "progress:  42 tensor(0.0112)\n",
      "tensor([0.0383], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.3916])\n",
      "tensor([0.0016], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.1576])\n",
      "tensor([0.0132], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.6883])\n",
      "tensor([0.0272], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3196])\n",
      "tensor([0.0108], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.2490])\n",
      "progress:  43 tensor(0.0108)\n",
      "tensor([0.0372], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.3857])\n",
      "tensor([0.0014], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.1492])\n",
      "tensor([0.0134], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.6945])\n",
      "tensor([0.0272], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3200])\n",
      "tensor([0.0105], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.2274])\n",
      "progress:  44 tensor(0.0105)\n",
      "tensor([0.0361], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.3800])\n",
      "tensor([0.0012], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.1411])\n",
      "tensor([0.0136], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.7007])\n",
      "tensor([0.0272], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3204])\n",
      "tensor([0.0101], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.2062])\n",
      "progress:  45 tensor(0.0101)\n",
      "tensor([0.0350], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.3744])\n",
      "tensor([0.0011], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.1332])\n",
      "tensor([0.0139], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.7067])\n",
      "tensor([0.0273], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3208])\n",
      "tensor([0.0098], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.1855])\n",
      "progress:  46 tensor(0.0098)\n",
      "tensor([0.0340], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.3689])\n",
      "tensor([0.0010], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.1254])\n",
      "tensor([0.0141], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.7125])\n",
      "tensor([0.0273], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3212])\n",
      "tensor([0.0094], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.1653])\n",
      "progress:  47 tensor(0.0094)\n",
      "tensor([0.0330], grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad: 1.0 3.1 tensor([-0.3635])\n",
      "tensor([0.0009], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.1178])\n",
      "tensor([0.0143], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.7182])\n",
      "tensor([0.0273], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3216])\n",
      "tensor([0.0091], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.1456])\n",
      "progress:  48 tensor(0.0091)\n",
      "tensor([0.0321], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.3583])\n",
      "tensor([0.0008], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.1104])\n",
      "tensor([0.0146], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.7238])\n",
      "tensor([0.0273], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3220])\n",
      "tensor([0.0088], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.1264])\n",
      "progress:  49 tensor(0.0088)\n",
      "tensor([0.0312], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.3532])\n",
      "tensor([0.0007], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.1032])\n",
      "tensor([0.0148], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.7293])\n",
      "tensor([0.0273], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3223])\n",
      "tensor([0.0085], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.1075])\n",
      "progress:  50 tensor(0.0085)\n",
      "tensor([0.0303], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.3482])\n",
      "tensor([0.0006], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.0961])\n",
      "tensor([0.0150], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.7346])\n",
      "tensor([0.0273], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3227])\n",
      "tensor([0.0082], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.0892])\n",
      "progress:  51 tensor(0.0082)\n",
      "tensor([0.0295], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.3433])\n",
      "tensor([0.0005], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.0892])\n",
      "tensor([0.0152], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.7398])\n",
      "tensor([0.0274], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3230])\n",
      "tensor([0.0080], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.0712])\n",
      "progress:  52 tensor(0.0080)\n",
      "tensor([0.0287], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.3386])\n",
      "tensor([0.0004], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.0825])\n",
      "tensor([0.0154], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.7449])\n",
      "tensor([0.0274], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3234])\n",
      "tensor([0.0077], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.0537])\n",
      "progress:  53 tensor(0.0077)\n",
      "tensor([0.0279], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.3339])\n",
      "tensor([0.0004], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.0759])\n",
      "tensor([0.0156], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.7498])\n",
      "tensor([0.0274], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3237])\n",
      "tensor([0.0075], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.0366])\n",
      "progress:  54 tensor(0.0075)\n",
      "tensor([0.0271], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.3294])\n",
      "tensor([0.0003], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.0695])\n",
      "tensor([0.0158], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.7547])\n",
      "tensor([0.0274], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3240])\n",
      "tensor([0.0072], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.0198])\n",
      "progress:  55 tensor(0.0072)\n",
      "tensor([0.0264], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.3249])\n",
      "tensor([0.0002], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.0632])\n",
      "tensor([0.0160], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.7594])\n",
      "tensor([0.0274], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3244])\n",
      "tensor([0.0070], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([1.0035])\n",
      "progress:  56 tensor(0.0070)\n",
      "tensor([0.0257], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.3206])\n",
      "tensor([0.0002], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.0571])\n",
      "tensor([0.0162], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.7641])\n",
      "tensor([0.0274], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3247])\n",
      "tensor([0.0068], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.9875])\n",
      "progress:  57 tensor(0.0068)\n",
      "tensor([0.0250], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.3164])\n",
      "tensor([0.0002], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.0511])\n",
      "tensor([0.0164], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.7686])\n",
      "tensor([0.0274], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3250])\n",
      "tensor([0.0066], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.9719])\n",
      "progress:  58 tensor(0.0066)\n",
      "tensor([0.0244], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.3122])\n",
      "tensor([0.0001], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.0452])\n",
      "tensor([0.0166], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.7730])\n",
      "tensor([0.0274], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3253])\n",
      "tensor([0.0064], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.9567])\n",
      "progress:  59 tensor(0.0064)\n",
      "tensor([0.0237], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.3082])\n",
      "tensor([9.7578e-05], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.0395])\n",
      "tensor([0.0168], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.7773])\n",
      "tensor([0.0275], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3255])\n",
      "tensor([0.0062], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.9418])\n",
      "progress:  60 tensor(0.0062)\n",
      "tensor([0.0231], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.3042])\n",
      "tensor([7.1960e-05], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.0339])\n",
      "tensor([0.0170], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.7815])\n",
      "tensor([0.0275], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3258])\n",
      "tensor([0.0060], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.9273])\n",
      "progress:  61 tensor(0.0060)\n",
      "tensor([0.0226], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.3004])\n",
      "tensor([5.0683e-05], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.0285])\n",
      "tensor([0.0171], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.7856])\n",
      "tensor([0.0275], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3261])\n",
      "tensor([0.0058], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.9131])\n",
      "progress:  62 tensor(0.0058)\n",
      "tensor([0.0220], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2966])\n",
      "tensor([3.3494e-05], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.0231])\n",
      "tensor([0.0173], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.7896])\n",
      "tensor([0.0275], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3264])\n",
      "tensor([0.0056], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.8993])\n",
      "progress:  63 tensor(0.0056)\n",
      "tensor([0.0215], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2929])\n",
      "tensor([2.0134e-05], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.0179])\n",
      "tensor([0.0175], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.7936])\n",
      "tensor([0.0275], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3266])\n",
      "tensor([0.0054], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.8857])\n",
      "progress:  64 tensor(0.0054)\n",
      "tensor([0.0209], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2893])\n",
      "tensor([1.0341e-05], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.0129])\n",
      "tensor([0.0177], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.7974])\n",
      "tensor([0.0275], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3269])\n",
      "tensor([0.0053], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.8725])\n",
      "progress:  65 tensor(0.0053)\n",
      "tensor([0.0204], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2858])\n",
      "tensor([3.9009e-06], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.0079])\n",
      "tensor([0.0178], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8011])\n",
      "tensor([0.0275], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3271])\n",
      "tensor([0.0051], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.8596])\n",
      "progress:  66 tensor(0.0051)\n",
      "tensor([0.0199], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2824])\n",
      "tensor([5.8208e-07], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([-0.0031])\n",
      "tensor([0.0180], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8048])\n",
      "tensor([0.0275], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3274])\n",
      "tensor([0.0050], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.8470])\n",
      "progress:  67 tensor(0.0050)\n",
      "tensor([0.0195], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2791])\n",
      "tensor([1.7728e-07], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0017])\n",
      "tensor([0.0182], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8084])\n",
      "tensor([0.0275], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3276])\n",
      "tensor([0.0048], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.8347])\n",
      "progress:  68 tensor(0.0048)\n",
      "tensor([0.0190], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2758])\n",
      "tensor([2.4881e-06], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0063])\n",
      "tensor([0.0183], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8119])\n",
      "tensor([0.0276], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3279])\n",
      "tensor([0.0047], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.8226])\n",
      "progress:  69 tensor(0.0047)\n",
      "tensor([0.0186], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2726])\n",
      "tensor([7.3305e-06], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0108])\n",
      "tensor([0.0185], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8153])\n",
      "tensor([0.0276], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3281])\n",
      "tensor([0.0046], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.8108])\n",
      "progress:  70 tensor(0.0046)\n",
      "tensor([0.0182], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2695])\n",
      "tensor([1.4523e-05], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0152])\n",
      "tensor([0.0186], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8186])\n",
      "tensor([0.0276], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3283])\n",
      "tensor([0.0044], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.7994])\n",
      "progress:  71 tensor(0.0044)\n",
      "tensor([0.0177], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2664])\n",
      "tensor([2.3898e-05], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0196])\n",
      "tensor([0.0188], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8218])\n",
      "tensor([0.0276], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3285])\n",
      "tensor([0.0043], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.7882])\n",
      "progress:  72 tensor(0.0043)\n",
      "tensor([0.0174], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2634])\n",
      "tensor([3.5300e-05], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0238])\n",
      "tensor([0.0189], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8250])\n",
      "tensor([0.0276], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3287])\n",
      "tensor([0.0042], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.7772])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress:  73 tensor(0.0042)\n",
      "tensor([0.0170], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2605])\n",
      "tensor([4.8573e-05], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0279])\n",
      "tensor([0.0190], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8281])\n",
      "tensor([0.0276], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3289])\n",
      "tensor([0.0041], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.7665])\n",
      "progress:  74 tensor(0.0041)\n",
      "tensor([0.0166], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2577])\n",
      "tensor([6.3595e-05], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0319])\n",
      "tensor([0.0192], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8312])\n",
      "tensor([0.0276], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3291])\n",
      "tensor([0.0040], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.7561])\n",
      "progress:  75 tensor(0.0040)\n",
      "tensor([0.0162], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2549])\n",
      "tensor([8.0201e-05], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0358])\n",
      "tensor([0.0193], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8341])\n",
      "tensor([0.0276], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3293])\n",
      "tensor([0.0039], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.7459])\n",
      "progress:  76 tensor(0.0039)\n",
      "tensor([0.0159], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2522])\n",
      "tensor([9.8276e-05], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0397])\n",
      "tensor([0.0195], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8370])\n",
      "tensor([0.0276], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3295])\n",
      "tensor([0.0038], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.7359])\n",
      "progress:  77 tensor(0.0038)\n",
      "tensor([0.0156], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2496])\n",
      "tensor([0.0001], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0434])\n",
      "tensor([0.0196], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8398])\n",
      "tensor([0.0276], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3297])\n",
      "tensor([0.0037], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.7261])\n",
      "progress:  78 tensor(0.0037)\n",
      "tensor([0.0152], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2470])\n",
      "tensor([0.0001], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0471])\n",
      "tensor([0.0197], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8426])\n",
      "tensor([0.0276], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3299])\n",
      "tensor([0.0036], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.7166])\n",
      "progress:  79 tensor(0.0036)\n",
      "tensor([0.0149], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2445])\n",
      "tensor([0.0002], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0506])\n",
      "tensor([0.0198], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8453])\n",
      "tensor([0.0276], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3301])\n",
      "tensor([0.0035], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.7073])\n",
      "progress:  80 tensor(0.0035)\n",
      "tensor([0.0146], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2420])\n",
      "tensor([0.0002], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0541])\n",
      "tensor([0.0200], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8479])\n",
      "tensor([0.0276], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3303])\n",
      "tensor([0.0034], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.6982])\n",
      "progress:  81 tensor(0.0034)\n",
      "tensor([0.0143], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2396])\n",
      "tensor([0.0002], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0575])\n",
      "tensor([0.0201], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8505])\n",
      "tensor([0.0277], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3304])\n",
      "tensor([0.0033], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.6894])\n",
      "progress:  82 tensor(0.0033)\n",
      "tensor([0.0141], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2372])\n",
      "tensor([0.0002], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0609])\n",
      "tensor([0.0202], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8530])\n",
      "tensor([0.0277], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3306])\n",
      "tensor([0.0032], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.6807])\n",
      "progress:  83 tensor(0.0032)\n",
      "tensor([0.0138], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2349])\n",
      "tensor([0.0003], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0641])\n",
      "tensor([0.0203], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8554])\n",
      "tensor([0.0277], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3307])\n",
      "tensor([0.0031], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.6722])\n",
      "progress:  84 tensor(0.0031)\n",
      "tensor([0.0135], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2327])\n",
      "tensor([0.0003], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0673])\n",
      "tensor([0.0204], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8578])\n",
      "tensor([0.0277], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3309])\n",
      "tensor([0.0031], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.6640])\n",
      "progress:  85 tensor(0.0031)\n",
      "tensor([0.0133], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2305])\n",
      "tensor([0.0003], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0704])\n",
      "tensor([0.0206], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8602])\n",
      "tensor([0.0277], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3311])\n",
      "tensor([0.0030], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.6559])\n",
      "progress:  86 tensor(0.0030)\n",
      "tensor([0.0130], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2283])\n",
      "tensor([0.0003], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0734])\n",
      "tensor([0.0207], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8625])\n",
      "tensor([0.0277], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3312])\n",
      "tensor([0.0029], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.6480])\n",
      "progress:  87 tensor(0.0029)\n",
      "tensor([0.0128], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2263])\n",
      "tensor([0.0004], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0764])\n",
      "tensor([0.0208], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8647])\n",
      "tensor([0.0277], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3314])\n",
      "tensor([0.0028], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.6403])\n",
      "progress:  88 tensor(0.0028)\n",
      "tensor([0.0126], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2242])\n",
      "tensor([0.0004], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0793])\n",
      "tensor([0.0209], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8669])\n",
      "tensor([0.0277], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3315])\n",
      "tensor([0.0028], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.6328])\n",
      "progress:  89 tensor(0.0028)\n",
      "tensor([0.0123], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2222])\n",
      "tensor([0.0004], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0821])\n",
      "tensor([0.0210], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8690])\n",
      "tensor([0.0277], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3317])\n",
      "tensor([0.0027], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.6255])\n",
      "progress:  90 tensor(0.0027)\n",
      "tensor([0.0121], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2203])\n",
      "tensor([0.0004], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0848])\n",
      "tensor([0.0211], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8711])\n",
      "tensor([0.0277], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3318])\n",
      "tensor([0.0027], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.6183])\n",
      "progress:  91 tensor(0.0027)\n",
      "tensor([0.0119], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2184])\n",
      "tensor([0.0005], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0875])\n",
      "tensor([0.0212], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8731])\n",
      "tensor([0.0277], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3319])\n",
      "tensor([0.0026], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.6113])\n",
      "progress:  92 tensor(0.0026)\n",
      "tensor([0.0117], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2165])\n",
      "tensor([0.0005], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0902])\n",
      "tensor([0.0213], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8751])\n",
      "tensor([0.0277], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3321])\n",
      "tensor([0.0025], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.6044])\n",
      "progress:  93 tensor(0.0025)\n",
      "tensor([0.0115], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2147])\n",
      "tensor([0.0005], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0927])\n",
      "tensor([0.0214], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8770])\n",
      "tensor([0.0277], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3322])\n",
      "tensor([0.0025], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.5977])\n",
      "progress:  94 tensor(0.0025)\n",
      "tensor([0.0113], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2129])\n",
      "tensor([0.0006], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0953])\n",
      "tensor([0.0215], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8789])\n",
      "tensor([0.0277], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3323])\n",
      "tensor([0.0024], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.5912])\n",
      "progress:  95 tensor(0.0024)\n",
      "tensor([0.0111], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2112])\n",
      "tensor([0.0006], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.0977])\n",
      "tensor([0.0215], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8808])\n",
      "tensor([0.0277], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3324])\n",
      "tensor([0.0024], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.5848])\n",
      "progress:  96 tensor(0.0024)\n",
      "tensor([0.0110], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2095])\n",
      "tensor([0.0006], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.1001])\n",
      "tensor([0.0216], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8826])\n",
      "tensor([0.0277], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3326])\n",
      "tensor([0.0023], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.5786])\n",
      "progress:  97 tensor(0.0023)\n",
      "tensor([0.0108], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2078])\n",
      "tensor([0.0007], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.1024])\n",
      "tensor([0.0217], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8844])\n",
      "tensor([0.0278], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3327])\n",
      "tensor([0.0023], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.5725])\n",
      "progress:  98 tensor(0.0023)\n",
      "tensor([0.0106], grad_fn=<MulBackward0>)\n",
      "\tgrad: 1.0 3.1 tensor([-0.2062])\n",
      "tensor([0.0007], grad_fn=<MulBackward0>)\n",
      "\tgrad: 2.0 5.0 tensor([0.1047])\n",
      "tensor([0.0218], grad_fn=<MulBackward0>)\n",
      "\tgrad: 3.0 6.9 tensor([0.8861])\n",
      "tensor([0.0278], grad_fn=<MulBackward0>)\n",
      "\tgrad: 4.0 9.2 tensor([-1.3328])\n",
      "tensor([0.0022], grad_fn=<MulBackward0>)\n",
      "\tgrad: 6.0 13.1 tensor([0.5665])\n",
      "progress:  99 tensor(0.0022)\n"
     ]
    }
   ],
   "source": [
    "eta = 0.01\n",
    "for epoch in range(100):\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        l = loss(x_val, y_val)\n",
    "        print(l)\n",
    "        l.backward()\n",
    "        print(\"\\tgrad:\", x_val, y_val, w.grad.data)\n",
    "        w.data = w.data - eta * w.grad.data\n",
    "        b.data = b.data - eta * b.grad.data\n",
    "\n",
    "        # manually set the gradient to zero after updating weight, bias\n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()\n",
    "\n",
    "    print(\"progress: \", epoch, l.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0229]) tensor([0.9748])\n"
     ]
    }
   ],
   "source": [
    "print(w.data, b.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict(atfer training) 5 tensor(11.0894)\n"
     ]
    }
   ],
   "source": [
    "print(\"predict(atfer training)\", 5, forward(5).data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制拟合的直线\n",
    "import numpy as np\n",
    "plt.scatter(x_data, y_data)\n",
    "x = np.linspace(1, 6, 100)\n",
    "y = w.data.numpy()[0] * x + b.data.numpy()[0]\n",
    "plt.plot(x, y, color='red')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
